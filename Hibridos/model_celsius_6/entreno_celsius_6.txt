[Running] python -u "c:\Users\alber\Desktop\TFG\Casos practicos\Hibridos\combinado_celsius.py"
Training new models...
Training Classical-Quantum Model:
Epoch 20/1500, Loss: 15.469902
Epoch 40/1500, Loss: 6.330499
Epoch 60/1500, Loss: 1.931919
Epoch 80/1500, Loss: 3.663632
Epoch 100/1500, Loss: 0.372495
Epoch 120/1500, Loss: 0.095232
Epoch 140/1500, Loss: 0.018030
Epoch 160/1500, Loss: 0.006879
Epoch 180/1500, Loss: 0.004251
Epoch 200/1500, Loss: 0.003401
Epoch 220/1500, Loss: 0.003067
Epoch 240/1500, Loss: 0.002876
Epoch 260/1500, Loss: 0.002737
Epoch 280/1500, Loss: 0.002619
Epoch 300/1500, Loss: 0.002513
Epoch 320/1500, Loss: 0.002413
Epoch 340/1500, Loss: 0.002319
Epoch 360/1500, Loss: 0.002230
Epoch 380/1500, Loss: 0.027153
Epoch 400/1500, Loss: 1.366838
Epoch 420/1500, Loss: 0.150667
Epoch 440/1500, Loss: 0.058055
Epoch 460/1500, Loss: 0.007217
Epoch 480/1500, Loss: 0.004558
Epoch 500/1500, Loss: 0.004249
Epoch 520/1500, Loss: 0.003941
Epoch 540/1500, Loss: 0.003710
Epoch 560/1500, Loss: 0.003503
Epoch 580/1500, Loss: 0.003347
Epoch 600/1500, Loss: 0.003259
Epoch 620/1500, Loss: 0.003173
Epoch 640/1500, Loss: 0.003091
Epoch 660/1500, Loss: 0.003011
Epoch 680/1500, Loss: 0.002946
Epoch 700/1500, Loss: 0.002908
Epoch 720/1500, Loss: 0.002871
Epoch 740/1500, Loss: 0.002834
Epoch 760/1500, Loss: 0.002798
Epoch 780/1500, Loss: 0.002766
Epoch 800/1500, Loss: 0.002748
Epoch 820/1500, Loss: 0.002730
Epoch 840/1500, Loss: 0.002712
Epoch 860/1500, Loss: 0.002693
Epoch 880/1500, Loss: 0.002677
Epoch 900/1500, Loss: 0.002668
Epoch 920/1500, Loss: 0.002658
Epoch 940/1500, Loss: 0.002649
Epoch 960/1500, Loss: 0.002640
Epoch 980/1500, Loss: 0.002631
Epoch 1000/1500, Loss: 0.002626
Epoch 1020/1500, Loss: 0.002621
Epoch 1040/1500, Loss: 0.002616
Epoch 1060/1500, Loss: 0.002611
Epoch 1080/1500, Loss: 0.002607
Epoch 1100/1500, Loss: 0.002604
Epoch 1120/1500, Loss: 0.002601
Epoch 1140/1500, Loss: 0.002599
Epoch 1160/1500, Loss: 0.002596
Epoch 1180/1500, Loss: 0.002594
Epoch 1200/1500, Loss: 0.002592
Epoch 1220/1500, Loss: 0.002591
Epoch 1240/1500, Loss: 0.002589
Epoch 1260/1500, Loss: 0.002588
Epoch 1280/1500, Loss: 0.002587
Epoch 1300/1500, Loss: 0.002586
Epoch 1320/1500, Loss: 0.002585
Epoch 1340/1500, Loss: 0.002584
Epoch 1360/1500, Loss: 0.002584
Epoch 1380/1500, Loss: 0.002583
Epoch 1400/1500, Loss: 0.002583
Epoch 1420/1500, Loss: 0.002582
Epoch 1440/1500, Loss: 0.002582
Epoch 1460/1500, Loss: 0.002581
Epoch 1480/1500, Loss: 0.002581
Epoch 1500/1500, Loss: 0.002581
Training Classical-Quantum Model took 426.39 seconds

Training Quantum-Classical Model:
Epoch 20/1500, Loss: 153.100983
Epoch 40/1500, Loss: 24.726868
Epoch 60/1500, Loss: 560.437683
Epoch 80/1500, Loss: 237.761993
Epoch 100/1500, Loss: 15.520200
Epoch 120/1500, Loss: 1.653705
Epoch 140/1500, Loss: 0.054677
Epoch 160/1500, Loss: 0.038917
Epoch 180/1500, Loss: 0.037720
Epoch 200/1500, Loss: 0.037130
Epoch 220/1500, Loss: 0.104401
Epoch 240/1500, Loss: 43.260307
Epoch 260/1500, Loss: 295.547394
Epoch 280/1500, Loss: 113.932709
Epoch 300/1500, Loss: 4.075734
Epoch 320/1500, Loss: 0.922582
Epoch 340/1500, Loss: 0.179115
Epoch 360/1500, Loss: 0.044233
Epoch 380/1500, Loss: 0.043789
Epoch 400/1500, Loss: 0.041651
Epoch 420/1500, Loss: 0.041582
Epoch 440/1500, Loss: 0.041523
Epoch 460/1500, Loss: 0.041471
Epoch 480/1500, Loss: 0.041418
Epoch 500/1500, Loss: 0.041363
Epoch 520/1500, Loss: 0.041327
Epoch 540/1500, Loss: 0.041298
Epoch 560/1500, Loss: 0.041269
Epoch 580/1500, Loss: 0.041239
Epoch 600/1500, Loss: 0.041208
Epoch 620/1500, Loss: 0.041187
Epoch 640/1500, Loss: 0.041171
Epoch 660/1500, Loss: 0.041154
Epoch 680/1500, Loss: 0.041137
Epoch 700/1500, Loss: 0.041120
Epoch 720/1500, Loss: 0.041107
Epoch 740/1500, Loss: 0.041099
Epoch 760/1500, Loss: 0.041090
Epoch 780/1500, Loss: 0.041080
Epoch 800/1500, Loss: 0.041071
Epoch 820/1500, Loss: 0.041064
Epoch 840/1500, Loss: 0.041059
Epoch 860/1500, Loss: 0.041054
Epoch 880/1500, Loss: 0.041049
Epoch 900/1500, Loss: 0.041043
Epoch 920/1500, Loss: 0.041040
Epoch 940/1500, Loss: 0.041037
Epoch 960/1500, Loss: 0.041034
Epoch 980/1500, Loss: 0.041032
Epoch 1000/1500, Loss: 0.041029
Epoch 1020/1500, Loss: 0.041027
Epoch 1040/1500, Loss: 0.041025
Epoch 1060/1500, Loss: 0.041024
Epoch 1080/1500, Loss: 0.041022
Epoch 1100/1500, Loss: 0.041021
Epoch 1120/1500, Loss: 0.041020
Epoch 1140/1500, Loss: 0.041019
Epoch 1160/1500, Loss: 0.041018
Epoch 1180/1500, Loss: 0.041018
Epoch 1200/1500, Loss: 0.041017
Epoch 1220/1500, Loss: 0.041017
Epoch 1240/1500, Loss: 0.041016
Epoch 1260/1500, Loss: 0.041016
Epoch 1280/1500, Loss: 0.041015
Epoch 1300/1500, Loss: 0.041015
Epoch 1320/1500, Loss: 0.041015
Epoch 1340/1500, Loss: 0.041014
Epoch 1360/1500, Loss: 0.041014
Epoch 1380/1500, Loss: 0.041014
Epoch 1400/1500, Loss: 0.041014
Epoch 1420/1500, Loss: 0.041014
Epoch 1440/1500, Loss: 0.041014
Epoch 1460/1500, Loss: 0.041013
Epoch 1480/1500, Loss: 0.041013
Epoch 1500/1500, Loss: 0.041013
Training Quantum-Classical Model took 407.63 seconds

Training Classical Model:
Epoch 20/1500, Loss: 752600832.000000
Epoch 40/1500, Loss: 0.029395
Epoch 60/1500, Loss: 0.001707
Epoch 80/1500, Loss: 0.000099
Epoch 100/1500, Loss: 0.000006
Epoch 120/1500, Loss: 0.000000
Epoch 140/1500, Loss: 0.000000
Early stopping at epoch 140 with loss 0.00000002
Training Classical Model took 0.03 seconds
Saving models...
Models saved successfully!

Classical-Quantum Model Test MSE: 0.0050
Classical-Quantum Model Test MAE: 0.0536
Classical-Quantum Model Accuracy (+-0.1 margin): 87.80%
Quantum-Classical Model Test MSE: 0.0356
Quantum-Classical Model Test MAE: 0.1625
Quantum-Classical Model Accuracy (+-0.1 margin): 27.80%
Classical Model Test MSE: 0.0000
Classical Model Test MAE: 0.0001
Classical Model Accuracy (+-0.1 margin): 100.00%

Model Comparison:
Classical model performs best with 100.00% accuracy

Detailed Temperature Prediction Comparison:
Index | F        | True C   | CQ Pred  | QC Pred  | Classical | CQ Acc?      | QC Acc?      | Class Acc?  
---------------------------------------------------------------------------------------------------------
0     | 77.1     | 25.07    | 24.98    | 25.26    | 25.07    | Yes          | No           | Yes         
1     | 37.4     | 3.02     | 2.97     | 2.9      | 3.02     | Yes          | No           | Yes         
2     | 6.9      | -13.95   | -14.05   | -13.9    | -13.95   | No           | Yes          | Yes         
3     | 7.7      | -13.48   | -13.5    | -13.53   | -13.48   | Yes          | Yes          | Yes         
4     | 10.4     | -11.99   | -12.01   | -12.06   | -11.99   | Yes          | Yes          | Yes         
5     | 84.0     | 28.91    | 28.9     | 28.99    | 28.91    | Yes          | Yes          | Yes         
6     | 91.1     | 32.82    | 32.86    | 32.73    | 32.82    | Yes          | Yes          | Yes         
7     | 12.3     | -10.95   | -11.04   | -11.11   | -10.95   | Yes          | No           | Yes         
8     | 23.6     | -4.67    | -4.67    | -4.9     | -4.67    | Yes          | No           | Yes         
9     | 16.6     | -8.58    | -8.61    | -8.77    | -8.58    | Yes          | No           | Yes         
10    | 18.6     | -7.43    | -7.47    | -7.63    | -7.43    | Yes          | No           | Yes         
11    | 83.7     | 28.75    | 28.77    | 28.83    | 28.75    | Yes          | Yes          | Yes         
12    | 33.2     | 0.67     | 0.67     | 0.5      | 0.67     | Yes          | No           | Yes         
13    | 31.1     | -0.48    | -0.45    | -0.68    | -0.48    | Yes          | No           | Yes         
14    | 22.7     | -5.14    | -5.08    | -5.38    | -5.14    | Yes          | No           | Yes         
15    | 60.8     | 15.99    | 16.01    | 16.2     | 15.99    | Yes          | No           | Yes         
16    | 37.9     | 3.29     | 3.24     | 3.18     | 3.29     | Yes          | No           | Yes         
17    | 74.4     | 23.57    | 23.52    | 23.8     | 23.57    | Yes          | No           | Yes         
18    | 20.6     | -6.36    | -6.28    | -6.56    | -6.36    | Yes          | No           | Yes         
19    | 78.8     | 25.99    | 25.87    | 26.21    | 25.99    | No           | No           | Yes         

CQ Model: 878/1000 predictions within +-0.1 margin (87.80%)
QC Model: 278/1000 predictions within +-0.1 margin (27.80%)
Classical Model: 1000/1000 predictions within +-0.1 margin (100.00%)

Reference: C = (F - 32) * 5/9

[Done] exited with code=0 in 859.827 seconds



